import cv2
from fer import FER
import numpy as np
import random
import webbrowser
from collections import deque

# === Initialisation du dÃ©tecteur FER avec MTCNN ===
detector = FER(mtcnn=True)

# === Messages selon lâ€™humeur ===
positive_messages = [
    "Super ! Continue Ã  sourire ğŸ˜„",
    "Tu rayonnes aujourdâ€™hui ğŸŒŸ",
    "FÃ©licitations ! Garde cette bonne Ã©nergie ğŸ’ª",
    "DÃ©fi du jour : fais sourire quelquâ€™un autour de toi ğŸ˜"
]

neutral_messages = [
    "On dirait que tu es calme... un petit sourire ? ğŸ˜Š",
    "Relax, tout va bien âœ¨",
    "Petit conseil : pense Ã  un bon souvenir ğŸ˜Œ",
    "Et si tu mettais ta musique prÃ©fÃ©rÃ©e ? ğŸ¶"
]

negative_quotes = [
    "Ne te dÃ©courage pas, les nuages passent toujours â˜€ï¸",
    "Chaque jour est une nouvelle chance ğŸ’«",
    "Respire, souris, recommence ğŸŒ¿",
    "Tu es plus fort(e) que tu ne le penses ğŸ’ª"
]

relaxing_songs = [
    "https://www.youtube.com/watch?v=2OEL4P1Rz04",  # Chill music
    "https://www.youtube.com/watch?v=1ZYbU82GVz4",  # Relaxing piano
    "https://www.youtube.com/watch?v=DWcJFNfaw9c"   # Calm background
]

# === Moyenne glissante pour lisser les Ã©motions ===
history = deque(maxlen=10)

# === RÃ©action selon lâ€™Ã©motion dominante ===
def react_to_emotion(emotion):
    if emotion == "happy":
        print("ğŸ‰", random.choice(positive_messages))
    elif emotion == "sad":
        print("ğŸ’¬", random.choice(negative_quotes))
        print("ğŸµ Je te propose dâ€™Ã©couter ceci pour te dÃ©tendre :")
        webbrowser.open(random.choice(relaxing_songs))
    elif emotion == "neutral":
        print("ğŸ™‚", random.choice(neutral_messages))

# === Capture webcam ===
cap = cv2.VideoCapture(0)
print("ğŸ¥ Assistant Ã©motionnel en cours... (Appuie sur 'q' pour quitter)")

last_emotion = None

while True:
    ret, frame = cap.read()
    if not ret:
        print("âš ï¸ Erreur : impossible d'accÃ©der Ã  la camÃ©ra.")
        break

    results = detector.detect_emotions(frame)

    if results:
        face = results[0]
        (x, y, w, h) = face["box"]
        emotions = face["emotions"]

        # Ajouter Ã  lâ€™historique pour lisser
        history.append(emotions)
        avg_emotions = {k: np.mean([h[k] for h in history]) for k in emotions}

        # Trouver lâ€™Ã©motion dominante
        dominant = max(avg_emotions, key=avg_emotions.get)

        # RÃ©agir uniquement si elle change
        if dominant != last_emotion:
            react_to_emotion(dominant)
            last_emotion = dominant

        # Couleur selon Ã©motion
        if dominant == "happy":
            color = (0, 255, 0)
        elif dominant == "sad":
            color = (0, 0, 255)
        else:
            color = (200, 200, 200)

        # === Afficher uniquement lâ€™Ã©motion dominante dans le cadre ===
        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)
        cv2.rectangle(frame, (x, y - 36), (x + w, y), color, -1)
        cv2.putText(frame, f"{dominant.upper()}", (x + 10, y - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), 2)

    cv2.imshow("Assistant Ã‰motionnel (Appuie sur 'q' pour quitter)", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# === LibÃ©ration des ressources ===
cap.release()
cv2.destroyAllWindows()
